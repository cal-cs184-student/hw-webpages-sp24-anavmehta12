<!DOCTYPE html>
<html lang="en">

    <head>
        <link rel="stylesheet" href="global.css">
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Tyndall Effect</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
            rel="stylesheet">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    </head>

    <body>
        <header>
            <h1>Tyndall Effect</h1>
            <h4>By Anav Mehta, Helena Su, Jared Basilio, and Ge Jin</h4>
        </header>
        <section id="abstract">
            <h2>Abstract</h2>
            <p>
                Through this project, our goal was to render the Tyndall Effect by shooting a ray through a volumetrically
                rendered medium. We approached the problem by first rendering both homogenous and heterogenous fog. We implemented
                ray marching where we had to account for the probabilities of absorption, scattering, and transmittance for each
                step. As for heterogenous fog, we implemented a Perlin Noise to vary the densities when traveling through the
                medium.
            </p>
            <div class="results">
                <div class="image">
                    <img src="./assets/lightbeam10_seed2468_0-08beta_o4_0-5_1500den.png">
                </div>
            </div>

        </section>
        <section id="technical-approach">
            <h2>Technical Approach</h2>
            <h3>Starting Point & Problem Context</h3>
            <p>
                Our starting point for this project is the CS 184 Project 3 ray tracer. The skeleton code includes the ray-scene
                intersection, acceleration structure, and physically based lighting and materials. While our starting point able
                to generate realistic images, it lacks of the implementation of spotlight and advanced volumetric rendering
                techniques that are required to depict phenomena like the Tyndall Effect. To address the issues, we expanded the
                render's capabilities by including a complex volumetric rendering,
                implementing both homogenous and heterogeneous fog.
            </p>
            <p>
                The Tyndall Effect is a optical phenomenon where light is scattered by particles that are dispersed in a medium.
                This effect causes the particles, like dust or droplets, become visible when light shines through them.

                In this project, by focusing on rendering fog and cloud effects, we essentially demonstrate the Tyndall Effect.
                Fog, consists of tiny water droplets that suspends in airs, will scatter the light passing through them.
            <h3>Homogenous Fog</h3>
            <h4>Initial idea</h4>
            <p>
                Initially, our approach to implementing homogenous fog, as suggested by Goodman, involved calculating a distance
                by selecting a uniform random number, ε, within the range [0, 1]. This value was then used to determine the time,
                t, which we interpreted as indicating either a surface or medium intersection. However, we encountered
                difficulties integrating this method with our existing ray tracing code. As a result, we opted for a different
                strategy based on ray marching.
            </p>
            <h4>Ray Marching</h4>
            <p>
                As we know that rays that pass through a medium lose energy due to absorption and out-scattering and gain energy
                due to in-scattering. We represent the scattering interaction through &sigma;<sub>s</sub>
                and the absorption interaction through. Beer-Lambert's Law \[T_{r} = {e^{-\sigma_{t}d}}.\] gives us the
                attenuation of the light traveling through some distance d where \[\sigma_{t} = {\sigma_{a} + \sigma_{s}}.\]As
                we are only dealing with homogenous mediums for now, the density term is constant. Just like how we use BSDFs for
                surface interactions, for media interactions we use a Phase Function since the outgoing direction can now be
                scattered in all directions vs just the hemisphere of directions in surface interactions. For isotropic volumes
                the phase function is simple being 1/4&pi; as it is equally scattered in all directions. However, for anisotropic
                volumes we
                use the Henyey-Greenstein Phase function
                \[p(\theta) = {{1 \over 4\pi}{{1 - g^2} \over [1 + g^2 - 2g*cos(\theta)]^{3/2}}}.\]
                that is parameterized by an asymmetry factor g controlling back and
                front scattering.
            </p>
            <p>
                We can finally put together ray marching as follows:
                <br>
                <br>
                For a certain number of steps, we march the ray's position forward for a chosen step size and for each step we:
            <ol>
                <li>
                    Calculate the fraction of light that is not absorbed or out-scattered traveling a segment of the
                    medium and update the transmission.
                </li>
                <li>
                    We sample the light to find the distance to the light and the direction to the light and calculate the
                    probability we scatter in a certain direction.
                </li>
                <li>
                    Calculate the in-scattering contribution by sampling the light and calculate the attenuation the light ray
                    travels to the point and update the running total of in-scattering light.
                </li>
            </ol>
            </p>
            <h4>Distance Attenuation Variation</h4>

            <p>by adjusting coefficients and power of the exponential attenuation function, we obtain different levels of radiance
                fall of in
                the area near the light. Here is a Desmos graph of different exponential fall of function:</p>
            <iframe src="https://www.desmos.com/calculator/wlycrs7jbf?embed" width="500" height="500"
                style="border: 1px solid #ccc" frameborder=0></iframe>
            <p>which in turn produce the follow different size of radiance fall of (haze area) in the fog near the area light.</p>
            <div class="results">
                <div class="image">
                    <img src="./assets/spheres_distance9thpower_focused_noroullete.png">
                    <code>9th power exponential attenuation function</code>
                </div>

                <div class="image">
                    <img src="./assets/spheres_distance5thpower_focused.png">
                    <code>5th power exponential attenuation function, big beta</code>
                </div>
            </div>
            <div class="results">
                <div class="image">
                    <img src="./assets/spheres_distance5thpower.png">
                    <code>5th power exponential attenuation function, small beta</code>
                </div>
            </div>

            <h3>Heterogenous Fog</h3>
            <p>
                For Heterogenous fog, the density varies throughout the medium instead of staying constant. To create this density
                field, we implemented a Perlin Noise function that generates smooth, continuous noise that is useful for
                simulating natural phenomena such as Fog. Perlin noise provides a natural variability within the cloud texture.
            </p>
            <h4>Perlin Noise Function</h4>
            <p>
                We implemented our Perlin Noise function by initially generating random normalized vectors that correspond to the
                corners of the 3D cube encompassing each sample point. To increase efficiency and reduce the number of directions
                generated, we used what's called a permutation table which randomly selects gradients to be at each corner of the
                cube. This table is accessed via a hash function hashing the (x, y, z) coordinates of the cube's corners. We
                interpolate between the dot products of the distance vectors—extending from the cube edges to our sample
                point—and the gradient vectors associated with each corner. This interpolation calculates the final noise
                value at the sample point, effectively producing the Perlin Noise.
            </p>

            <h4>Updated Ray Marching</h4>
            <p>
                A Heterogenous medium changes our ray marching algorithm since the densities along our light ray vary as it
                travels through the medium thus our estimation for the in-scattering term is different so we must ray march
                our light ray. While we march our light ray we accumulate density values along each sample along the ray. We
                replace our constant density with our Perlin Noise function and sample at each point for both rays.
            </p>
            <div class="results">
                <div class="image">
                    <img src="./assets/HomogenousFog1.png">
                    <code>Homogenous Fog rendering of ./dae/sky/CBSpheres.dae</code>
                </div>
                <div class="image">
                    <img src="./assets/HeterogenousFog1.png">
                    <code>Heterogenous Fog rendering of ./dae/sky/CBSpheres.dae</code>
                </div>
            </div>
            <h4>Perlin Noise Octave</h4>
            <p>While Perlin noise are commonly used in generating natural texture, the addition of octaves give clouds the extra
                furry effect and additional layer of detail and complexity. This method invovles with combining several Perlin
                Noise
                function at different frequencies and amplitudes. When generating texture like clouds, using multiple octaves
                allows
                for creating more varied patterns. The low frequency Perlin noise provides a broad and main shapes of the cloud.
                The second and higher octave, on the other hand, provides variation in the cloud's edges and them more
                natural-looking.

                Here is a nice chart
                from <a href="https://eev.ee/blog/2016/05/29/perlin-noise/">.</a>
            <div class="results">
                <div class="image">
                    <img src="./assets/octave.png">
                    <code>octave function</code>
                </div>

            </div>
            <p>Different octaves and persistence values render clouds of different fluffiness:</p>
            <div class="results">
                <div class="image">
                    <img src="./assets/boundaryless_cloudish_z0-5_o3_0-7_inroom_better_6000den.png">
                    <code>cloud with 3 octave and 0.7 persistence</code>
                </div>
                <div class="image">
                    <img src="./assets/boundaryless_cloudish_z0-5_o4_0-5_inroom_1000den.png">
                    <code>cloud with 4 octave and 0.5 persistence</code>
                </div>

            </div>
            <div class="results">
                <div class="image">
                    <img src="./assets/boundaryless_cloudish_z0-5_o5_0-7_inroom_1000den.png">
                    <code>cloud with 5 octave and 0.7 persistence</code>
                </div>
                <div class="image">
                    <img src="./assets/boundaryless2_cloudish_z0-5_o3_0-7_inroom_better_6000den.png">
                    <code>cloud with 3 octave and 0.7 persistence</code>
                </div>
            </div>

            </p>
            <h3>Spot Light Sampling</h3>
            <p>
                We wanted to create realistic soft light beams through the fog to visualize how light scatters through a
                medium.
                To do this we filled in the spotlight constructor and the associated
                <code>sample_l</code> function. In the <code>sample_l</code>
                function, the function starts by calculating the vector <code>d</code> which represents the direction from
                the object to the light source. From here, we use dot product to calculate the angle between light
                direction and
                the vector pointing toward the object. We denote the angle as <code>spot_angle</code>
            </p>
            <p>
                If the <code>spot_angle</code>is less than the predefined angle of the spotlight, it indicates the object
                is
                within the light's cone and the illumination should be calculated. The <code> falloff </code> is
                calculated to
                reflect
                the reduction of light intensity as the angle increases from the central axis of the spotlight.
                The solid angle is \( \Omega = 2\pi (1 - \cos(\text{angle})) \)

                The probability distribution function is inversely proportional to the solid angle of the cone, as
                follows:

                \[ p = \frac{1}{\Omega} = \frac{1}{2\pi (1 - \cos(\text{angle}))} \]

                By adjusting the PDF according to the solid angle, the function ensures the density reflects the physical
                behavior
                of a spotlight, where more light is concentrated in a narrow angle. The function will return the light
                radiance
                scaled by the falloff. If the object is outside the spotlight's angle, the function returns a zero vector,
                indicating there's no light contribution, which effective handles objects lying outside the light beam.

            </p>
            <div class="results">
                <div class="image">
                    <img src="./assets/SpotlightBunny.png">
                    <code>Spotlight on Bunny</code>
                </div>

                <div class="image">
                    <img src="./assets/SpotlightBunnyRedFog.png">
                    <code>Spotlight on Bunny through Red Fog</code>
                </div>

            </div>
        </section>
        <section id="problems-encountered">
            <h2>Problems Encountered</h2>
            <h4>Dae file generation</h4>
            <p>
                Implementing light beams required new having a new
                <code>.dae</code>
                file
                that included a new spot light light rather than an area light or a point light. This was easier said than done.
                Through the Homework 3 Contest Ed Thread, many comments suggested that we hard code our spot light into the
                <code>.dae</code>
                file
                or did the tedious act of modeling our spotlight in Blender 4+, export to Collada (.dae), import into Blender 2.7,
                export to Collada Again,
                then utilize in our renderer. This was very tedious as it required multiple steps to create a singular file. At
                first, we were unsuccessful
                as it only showed a black image or an image that was uniformly lit by the spotlight. We eventually found that
                relative positions for light sources
                were not maintained when reexported. Therefore, changing the light source at the top of any
                <code>.dae</code>
                file
                in prefix with
                <i>CB</i>
                was moved on
                above the box, leading to no light emitting within the box hence the black image. Additionally, the already
                implement
                <code>.dae</code>
                files had
                a CGL rendering technique for the lights. Initially, this influenced some debug approaches that ultimately didn't
                work such as hardcoding the spot lights
                or researching this CGL method described.
            </p>
        </section>
        <section id="lessons-learned">
            <h2>Lessons Learned</h2>
            <p>Understand the underlying math principles first: Debugging the rendering code is hard as it is challenging to
                trace errors back to their source. For instance, in the creating a spotlight, it's essential to understand the
                Monte Carlo Integration on the 3D cone shape object. Without a deep understanding of the math involved,
                identifying the root cause of such problems becomes significantly more complex.
            </p>
            <p> To breakdown a big goal into smaller milestones: it was hard for us to get started on rendering the Tyndall Effect
                as it involved complicated algorithms. If instead we had just set a series of incremental targets, we could have
                made this project easier. Initially, we could have focused on understanding the physical principles and math
                models behind light scattering. Then we could have changed the BSDF to achieve a more realistic effect. Following
                this, we could have refined our model by incrementally integrating more complex calculations, such as cloud
                simulation. Each milestone provides us an opportunities to test, optimize, and refine our ideas - helping us to
                make progress easily.
            </p>
        </section>

        <section id="next-steps">
            <h2>Next Steps</h2>
            <h4>Color Scattering</h4>
            <p>

                We attempted rayleigh scattering by having blue color exponentially decaying throughout distance, and red color
                exponentially increasing throughout distance. This is supposed to give a blue cloud and yellow rays through the
                cloud (similar to the sunset), but we are not able to completely incorporate ray marching of the cloud with
                recursive
                bounces of the original ray tracing mechanism. We have tried dynamically shifting the color of L_out, the emission
                of light or material based on the average density from the hit point to the light source and the rayleigh
                scattering formula, but more work needs to be done.
            </p>
            <h4>Better Light Shafts</h4>
            <p>
                We achieved shining a spotlight path, but better light shafts should depend on the varying density of cloud,
                leaving shadows and light spots in the scene. We have tried sampling the average density of fog from sample point
                to hit point and adjusting attenuation accordingly, but the generation of our cloud is a 2D shell instead of a 3D
                volume, which creates discrepancy between light shafts and the density of cloud.
            </p>
        </section>

        <section id="Presentation">
            <a href="https://www.youtube.com/watch?v=--lKMA1KBt4">Presentation Video</a>
            <a href=" https://docs.google.com/presentation/d/1fdTJ2BFZyDH3qxRIoOQSyJI1OL9O9ytlayWLHRQ2p2w/edit?usp=sharing">Presentation
                Slides</a>
        </section>
        <section id="references">
            <h2>References</h2>
            <ol>
                <li>
                    <a
                        href="https:
                         //www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html">
                        https://www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html
                    </a>
                </li>
                <li>
                    <a href="https://en.wikipedia.org/wiki/Perlin_noise">https://en.wikipedia.org/wiki/Perlin_noise</a>
                </li>
                <li>
                    <a href="https://inriarhal.scalnce/snnra-00288758i-7
n">https://inria.hal.science/inria-00288758/en</a>
                </li>

                <li>
                    <a href=" https://cseweb.ucsd.edu/~viscomp/classes/cse168/sp20/lectures/168-lecture15.pdf
                    "> https://cseweb.ucsd.edu/~viscomp/classes/cse168/sp20/lectures/168-lecture15.pdf
                    </a>
                </li>
            </ol>
        </section>
        <section id="team-contributions">
            <h2>Contributions</h2>
            <ul>
                <li>Anav Mehta: Implemented initial Heterogenous and Homogenous Fog code. Implemented Perlin Noise.</li>
                <li>Helena Su: Worked on creating the final deliverable being the heterogenous and homogenous cloud through
                    Rayleigh scattering. </li>
                <li>Jared Basilio: Worked on .dae File Generation Spotlight Approach, HW 3 Source Code</li>
                <li>Ge Jin: Worked on implementing homogenous fog and implementing the spotlight generation </li>
            </ul>
        </section>
    </body>

</html>